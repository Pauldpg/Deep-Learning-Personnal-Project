{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Package importation"
      ],
      "metadata": {
        "id": "KbE4DKkOzxqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from packaging import version\n",
        "import matplotlib.animation\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import random\n",
        "\n",
        "\n",
        "assert sys.version_info >= (3, 7)\n",
        "\n",
        "if \"google.colab\" in sys.modules or \"kaggle_secrets\" in sys.modules:\n",
        "    %pip install -q -U gym\n",
        "    %pip install -q -U gym[classic_control,box2d,atari,accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paQ0dSwly3me",
        "outputId": "ffe416b1-7f71-4432-8c74-f1ead308ae67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class and Functions"
      ],
      "metadata": {
        "id": "7LHOKR1e0AtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_PATH = Path() / \"images\" / \"rl\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "metadata": {
        "id": "HIeVv20d0C9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_environment(env, figsize=(5, 4)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    img = env.render()\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    return img"
      ],
      "metadata": {
        "id": "CyTYpGGj0GNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_scene(num, frames, patch):\n",
        "    patch.set_data(frames[num])\n",
        "    return patch,\n",
        "\n",
        "def plot_animation(frames, repeat=False, interval=40):\n",
        "    fig = plt.figure()\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "    anim = matplotlib.animation.FuncAnimation(\n",
        "        fig, update_scene, fargs=(frames, patch),\n",
        "        frames=len(frames), repeat=repeat, interval=interval)\n",
        "    plt.close()\n",
        "    return anim\n",
        "\n",
        "def show_one_episode(policy, n_max_steps=200, seed=42):\n",
        "    frames = []\n",
        "    env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
        "    np.random.seed(seed)\n",
        "    obs, info = env.reset(seed=seed)\n",
        "    for step in range(n_max_steps):\n",
        "        frames.append(env.render())\n",
        "        action = policy(obs)\n",
        "        obs, reward, done, truncated, info = env.step(action)\n",
        "        if done or truncated:\n",
        "            break\n",
        "    env.close()\n",
        "    return plot_animation(frames)"
      ],
      "metadata": {
        "id": "mMSshilq1XL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlexibleMLP(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super(FlexibleMLP, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.activations = nn.ModuleList()\n",
        "\n",
        "        for i in range(len(layers) - 1):\n",
        "            layer = nn.Linear(layers[i], layers[i+1])\n",
        "\n",
        "            # LeCun initialization\n",
        "            nn.init.normal_(layer.weight, mean=0.0, std=np.sqrt(1 / layers[i]))\n",
        "            nn.init.normal_(layer.bias, mean=0.0, std=np.sqrt(1 / layers[i]))\n",
        "\n",
        "            self.layers.append(layer)\n",
        "            # Add ReLU activation after each layer except the last\n",
        "            if i < len(layers) - 2:\n",
        "                self.activations.append(nn.ReLU())\n",
        "            else:\n",
        "                # Placeholder for the last layer's activation\n",
        "                self.activations.append(nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x, return_last_hidden=False):\n",
        "        last_hidden = None\n",
        "\n",
        "        for layer, activation in zip(self.layers[:-1], self.activations[:-1]):\n",
        "            x = activation(layer(x))\n",
        "            last_hidden = x  # Update last_hidden at each hidden layer\n",
        "\n",
        "        # Apply the last layer without ReLU (or Identity for the placeholder)\n",
        "        x = self.layers[-1](x)\n",
        "\n",
        "        if return_last_hidden:\n",
        "            return x, last_hidden\n",
        "        return x\n",
        "\n",
        "    def set_seed(seed_value=42):\n",
        "      \"\"\"Set seed for reproducibility.\"\"\"\n",
        "      np.random.seed(seed_value)  # Set NumPy seed\n",
        "      torch.manual_seed(seed_value)  # Set PyTorch seed\n",
        "      random.seed(seed_value)  # Set Python random seed\n",
        "\n",
        "      # If you are using CUDA:\n",
        "      if torch.cuda.is_available():\n",
        "          torch.cuda.manual_seed(seed_value)\n",
        "          torch.cuda.manual_seed_all(seed_value)  # For multi-GPU\n",
        "          torch.backends.cudnn.deterministic = True\n",
        "          torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "YBVVVZXD3rnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(num_epochs: int,\n",
        "                train_loader: DataLoader,\n",
        "                criterion,\n",
        "                optimizer,\n",
        "                model):\n",
        "  # Training loop\n",
        "  for epoch in range(num_epochs):\n",
        "      for inputs, targets in train_loader:\n",
        "          # Forward pass\n",
        "          outputs = model(inputs) #input à l'objet qui donne output\n",
        "          loss = criterion(outputs, targets) #criterion = loss function\n",
        "\n",
        "          # Backward and optimize\n",
        "          optimizer.zero_grad() # kill old gradients\n",
        "          loss.backward() # compute new gradients\n",
        "          optimizer.step() # perform the step of gradient descent\n",
        "\n",
        "      if (epoch+1) % 20 == 0:\n",
        "          print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "uPZc1VJD71Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def play_one_step(env, obs, model, loss_fn):\n",
        "    obs = torch.tensor(obs[np.newaxis], dtype=torch.float32)\n",
        "    model.train()\n",
        "    with torch.enable_grad():\n",
        "        left_proba = model(obs)\n",
        "        action = (torch.rand(1, 1) > left_proba).float()\n",
        "        y_target = torch.tensor([[1.]]) - action\n",
        "        loss = torch.mean(loss_fn(left_proba, y_target))\n",
        "\n",
        "\n",
        "    grads = [param.grad for param in model.parameters() if param.grad is not None]\n",
        "\n",
        "    obs, reward, done, truncated, info = env.step(int(action.item()))\n",
        "    model.zero_grad()\n",
        "\n",
        "    return obs, reward, done, truncated, grads\n"
      ],
      "metadata": {
        "id": "D01_L2cc-u7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def play_multiple_episodes(env, n_episodes, n_max_steps, model, loss_fn):\n",
        "    all_rewards = []\n",
        "    all_grads = []\n",
        "    for episode in range(n_episodes):\n",
        "        current_rewards = []\n",
        "        current_grads = []\n",
        "        obs, info = env.reset()\n",
        "        for step in range(n_max_steps):\n",
        "            obs, reward, done, truncated, grads = play_one_step(\n",
        "                env, obs, model, loss_fn)\n",
        "            current_rewards.append(reward)\n",
        "            current_grads.append(grads)\n",
        "            if done or truncated:\n",
        "                break\n",
        "\n",
        "        all_rewards.append(current_rewards)\n",
        "        all_grads.append(current_grads)\n",
        "\n",
        "    return all_rewards, all_grads"
      ],
      "metadata": {
        "id": "D-avNfrW_IoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discount_rewards(rewards, discount_factor):\n",
        "    discounted = np.array(rewards)\n",
        "    for step in range(len(rewards) - 2, -1, -1):\n",
        "        discounted[step] += discounted[step + 1] * discount_factor\n",
        "    return discounted\n",
        "\n",
        "def discount_and_normalize_rewards(all_rewards, discount_factor):\n",
        "    all_discounted_rewards = [discount_rewards(rewards, discount_factor)\n",
        "                              for rewards in all_rewards]\n",
        "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
        "    reward_mean = flat_rewards.mean()\n",
        "    reward_std = flat_rewards.std()\n",
        "    return [(discounted_rewards - reward_mean) / reward_std\n",
        "            for discounted_rewards in all_discounted_rewards]"
      ],
      "metadata": {
        "id": "D1h9hLp3_QSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "General Settings and Environment setup"
      ],
      "metadata": {
        "id": "Kagf2M_P0MSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)\n",
        "plt.rc('animation', html='jshtml')"
      ],
      "metadata": {
        "id": "cOwJUQGay7QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")"
      ],
      "metadata": {
        "id": "5UhNaf__zDEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs, info = env.reset(seed=42)"
      ],
      "metadata": {
        "id": "ksxD8W4UzMMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_environment(env)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "SxotLdCRzuku",
        "outputId": "b236bd63-81c9-4d97-f441-1a6768f999a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FlexibleMLP.set_seed(42)\n",
        "width = 100\n",
        "model_architecture = [obs.shape[1], width, 2] #premier layer = nombre de parametre, second = 100 arbitraire, dernier = 1 pour donner une fonction\n",
        "model = [FlexibleMLP(model_architecture)] #Chaque model possède la mêm architecture / modèle devient un objet flexible mlp"
      ],
      "metadata": {
        "id": "dCfsvITo770o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iterations = 150\n",
        "n_episodes_per_update = 10\n",
        "n_max_steps = 200\n",
        "discount_factor = 0.95\n",
        "\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    all_rewards, all_grads = play_multiple_episodes(\n",
        "        env, n_episodes_per_update, n_max_steps, model, loss_fn)\n",
        "\n",
        "    # extra code – displays some debug info during training\n",
        "    total_rewards = sum(map(sum, all_rewards))\n",
        "    print(f\"\\rIteration: {iteration + 1}/{n_iterations},\"\n",
        "          f\" mean rewards: {total_rewards / n_episodes_per_update:.1f}\", end=\"\")\n",
        "\n",
        "    all_final_rewards = discount_and_normalize_rewards(all_rewards,\n",
        "                                                       discount_factor)\n",
        "    all_mean_grads = []\n",
        "    for var_index in range(len(model.trainable_variables)):\n",
        "        mean_grads = tf.reduce_mean(\n",
        "            [final_reward * all_grads[episode_index][step][var_index]\n",
        "             for episode_index, final_rewards in enumerate(all_final_rewards)\n",
        "                 for step, final_reward in enumerate(final_rewards)], axis=0)\n",
        "        all_mean_grads.append(mean_grads)\n",
        "\n",
        "    optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables))"
      ],
      "metadata": {
        "id": "zi3T8mY47731"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the deep neural network model\n",
        "num_seeds = 20 #on test avec differentes seed le model\n",
        "\n",
        "FlexibleMLP.set_seed(42)\n",
        "width = 100\n",
        "model_architecture = [X_train.shape[1], width, 1] #premier layer = nombre de parametre, second = 100 arbitraire, dernier = 1 pour donner une fonction\n",
        "models = [FlexibleMLP(model_architecture) for seed in range(num_seeds)] #Chaque model possède la mêm architecture / modèle devient un objet flexible mlp\n",
        "\n",
        "# Proceed with the rest of the setup (loss, optimizer) and training loop as before\n",
        "# Loss and optimizer\n",
        "for seed in range(num_seeds): #Un model pour chaque seed\n",
        "\n",
        "  FlexibleMLP.set_seed(seed)\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = optim.Adam(models[seed].parameters(), lr=0.0001) #, weight_decay=0)  # Using Adam optimizer for better performance with deep networks\n",
        "\n",
        "  train_model(num_epochs=200,\n",
        "              train_loader=train_loader,\n",
        "              criterion=criterion,\n",
        "              optimizer=optimizer,\n",
        "              model=models[seed])"
      ],
      "metadata": {
        "id": "5LZCp50C12HX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}